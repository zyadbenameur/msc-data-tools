---
title: "Systèmes de recommandation en R"
authors: 
  - Patrik Carvalho-Carreira
  - Zyad Benameur
date: "2020-05-16"
toc: true
description: Tutoriel sur les méthodes de systèmes de recommandations, présentant les ressources disponibles sur `R`, une revue de litérature et un example d'implémentation.
slug: Recommander-systems
categories:
  - Projects
tags:
  - R
  - Recommander system
  - Tutorial
  - Article reviews
  - R libraries
---


<div id="TOC">
true
</div>

<div id="recommender-systems" class="section level1">
<h1>Recommender systems</h1>
<p>Au cours des dernières années, certaines grandes entreprises ont connu un essor phénoménal grâce aux données de leurs utilisateurs. La collecte de ses données leurs permette de prendre de meilleures décisions et invite l’utilisateur a utilisé davantage leurs plateformes. Cette fidélisation et satisfaction de la clientèle est au coeur des systèmes de recommandations.</p>
<p>Selon <em><strong></strong></em>, les systèmes de recommandation (<em><strong>S.R.</strong></em>), dans leur forme la plus simple, peuvent être vu comme un système de classification. Cette approche permet aux systèmes de recommandaions de proposer des produits ou services “personnalisés” selon les préférences de l’utilisateur. Effectivement, Ces systèmes permettent aussi aux entreprises d’augmenter le nombre d’items vendus, de vendre plus de produits divers et d’avoir une meilleure compréhension des besoins de leurs clients. <em><strong></strong></em></p>
<div id="importance-dans-lindustrie" class="section level2">
<h2>Importance dans l’industrie</h2>
<p>Afin de mettre l’emphase sur l’importance des <em><strong>S.R.</strong></em>, une étude de McKinsey <a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> révèle que 35% des achats de consommateurs sur Amazon provient d’algorithmes basé sur la recommandation de produits. Dans le même ordre d’idée, 75% de ce qui est visionné par les utilisateurs de NetFlix proviennent de leurs algorithmes de recommandations. En 2006 <a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>, Netflix avait d’ailleurs lancé une compétition avec un prix d’un million si une équipe pouvait augmenter la performance de leurs <em><strong>S.R.</strong></em> de 10%.</p>
</div>
<div id="utilité" class="section level2">
<h2>Utilité</h2>
<p>Voici les utilités principales des <em><strong>S.R.</strong></em>, autant du côté de l’utilisateur, que du fournisseur de service. Cette liste n’est pas complète ni exaustive, mais couvre largement les principaux attraits des <em><strong>S.R.</strong></em>.</p>
<table>
<caption><span id="tab:unnamed-chunk-1">Table 1: </span>Utilité des <em><strong>S.R.</strong></em> (<link><a href="https://www.researchgate.net/publication/227268858_Recommender_Systems_Handbook">Ricci, F. et al. 2018</a>)</caption>
<thead>
<tr class="header">
<th align="left">Fournisseur de service</th>
<th align="left">Utilisateur</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Vendre plus d’items</td>
<td align="left">Trouver les bons items</td>
</tr>
<tr class="even">
<td align="left">Vendre plus de variété d’items</td>
<td align="left">Trouver la bonne séquence d’items</td>
</tr>
<tr class="odd">
<td align="left">Augmenter la satisfaction des clients</td>
<td align="left">Meilleure expérience de navigation</td>
</tr>
<tr class="even">
<td align="left">Augmenter la fidélité des clients</td>
<td align="left">Avoir des recommandations crédible</td>
</tr>
<tr class="odd">
<td align="left">Meilleure compréhension des attentes des clients</td>
<td align="left">Trouver le bon package d’items</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="revue-de-littérature" class="section level1">
<h1>Revue de littérature</h1>
<p>Dans cette section, on présente quelques articles complets couvrants différents aspects touchants aux <em><strong>S.R.</strong></em>. On a voulus offrir une variétés d’articles et d’études qui donnera au lecteur une compréhension globale et précise des différents modèles et approches, classiques et plus récentes, utilisées en <em><strong>S.R.</strong></em>. À noter que certains de ces articles proposent également des revues de littératures.</p>
<ul>
<li><strong><em></em></strong> et
<em><strong></strong></em> ont réalisés deux revues complètes sur les <em><strong>S.R.</strong></em>, couvrant les approches les plus populaires : <em>Content Based, Collaborative Filtering et Hybrid</em>.<br />
Le deuxième article inclut deux chapitres supplémentaires discutants deux aspects plus récents dans les <em><strong>S.R.</strong></em>: <em>Le contexte et les médias-sociaux</em>.<br />
</li>
<li>L’article suivant, par <strong><em></em></strong>, offre une revue complète sur les <em><strong>S.R.</strong></em> <em>“à filtrage collaboratif”</em>, incluant une liste de revues similaires précédentes. Les auteurs exposent les méthodes classiques, les méthodes adaptées aux médias sociaux, en passant par les approches des modèles hybrides.<br />
</li>
<li><strong><em></em></strong> proposent dans leur article une analyse des dernières tendances en matière de <em><strong>S.R.</strong></em> <em>“Content-Based”</em>, ainsi qu’une liste d’articles parus sur le sujet.<br />
</li>
<li>Voici un article par <strong><em></em></strong> offrant une revue de litérature sur les <em><strong>S.R.</strong></em> <em>“Hybrid”</em>.<br />
</li>
<li>L’apprentissage profond dans les <em><strong>S.R.</strong></em> est de plus en plus utilisé. Voici deux articles par
<strong><em></em></strong> et
<strong><em></em></strong>
offrants des revues sur les <em><strong>S.R.</strong></em> <em>“deep learning based”</em>.<br />
</li>
<li>Voici un article par <strong><em></em></strong>
offrant une revue de littérature des méthodes d’apprentissage machine utilisées dans les <em><strong>S.R.</strong></em>.<br />
</li>
<li>Finalement, voici un livre complet par <em><strong></strong></em>
disponible gratuitement, dont l’objet d’étude est les <em><strong>S.R.</strong></em>, offrant une revue complète de différentes techniques, ainsi que plusieurs chapitres sur l’évaluation des <em><strong>S.R.</strong></em>. <link><a href="https://www.researchgate.net/publication/227268858_Recommender_Systems_Handbook">(Livre disponible )</a></li>
</ul>
</div>
<div id="description-des-méthodes" class="section level1">
<h1>Description des méthodes</h1>
<p>Il existe plusieurs approches différentes pour les <em><strong>S.R.</strong></em>. Ces approchent se différencient principalement par les algorithmes utilisés. On peut identifier 5 principales approches basées sur une taxonomie proposée par <strong><em></em></strong> :
 <br />
 <br />
 </p>
<table>
<tbody>
<tr class="odd">
<td align="center"><strong>Knowledge Based</strong></td>
</tr>
<tr class="even">
<td align="center"><strong>Demographic Based</strong></td>
</tr>
<tr class="odd">
<td align="center"><strong>Content Based</strong></td>
</tr>
<tr class="even">
<td align="center"><strong>Collaborative Based</strong></td>
</tr>
<tr class="odd">
<td align="center"><strong>Hybrid</strong></td>
</tr>
</tbody>
</table>
<p>Dans la section suivante, on présente les grandes lignes de ces différentes approches.</p>
<div id="knowledge-based" class="section level2">
<h2>Knowledge Based</h2>
<p>Ces <em><strong>S.R.</strong></em> sont adaptés aux items qui sont très peu acheté par un utilisateur. l’exemple donné ici est celui de l’achat d’une maison. Il n’est pas envisageable d’avoir un grand historique d’achat par utilisateur pour ce genre d’item, dans ce cas, l’utilisation d’un <em><strong>S.R.</strong></em> “<em>Knowledge based</em>” est utile.<br />
Ce type de <em><strong>S.R.</strong></em> utilise les connaissances liés au domaine ou à l’industrie pour pouvoir faire des recommandations en agissant comme un système de filtrage avancé, respectant les conditions énumérées par l’utilisateur en lui proposant les résultats pertinents.</p>
</div>
<div id="demographic-based" class="section level2">
<h2>Demographic Based</h2>
<p>Ce type de <em><strong>S.R.</strong></em> se base sur l’assomption que les recommendations peuvent se faire en utilisant les attributs démographiques des utilisateurs (Âge, sexe, langue, etc…).<br />
Par exemple, on pourra recommander un contenu à un jeune utilisateur qui est populaire auprés des jeunes du même âge.</p>
</div>
<div id="content-based" class="section level2">
<h2>Content Based</h2>
<p>Les <em><strong>S.R.</strong></em> “content based” apprennent à faire des recommandations à partir des items que l’utilisateur a apprécié/acheté par le passé. Le <em><strong>S.R.</strong></em> peut calculer une similarité entre les items à partir de leurs attributs, et recommander les items les plus proches à ceux précédement appréciés par l’utilisateur.<br />
Par exemple, si l’utilisateur à aimé un film de comédie, le <em><strong>S.R.</strong></em> pourra lui recommander d’autres films du même genre.</p>
</div>
<div id="collaborative-based" class="section level2">
<h2>Collaborative Based</h2>
<p>Les <em><strong>S.R.</strong></em> collaboratifs utilisent la communauté d’utilisateurs afin de générer des recommandations. Le cas le plus simple est de recommander à l’utilisateur des items que des utilisateurs similaires ont appréciés par le passé.<br />
Il y a différentes manières de calculer cette similarité en fonction du type de recommandation.<br />
Deux grandes approches sont populaires dans les <em><strong>S.R.</strong></em> collaboratifs : “Item based” et “User based”.</p>
<ul>
<li><strong><em>Item based collaborative filtering RS</em></strong><br />
utilise pour les recommandations à travers la popularité des associations entre produits. Par exemple, si plusieurs utilisateurs aiment un livre A et B, quand un nouvel utilisateur indqique qu’il aime le livre A, on pourrat lui recommander le livre B.<br />
</li>
<li><strong><em>User based collaborative filtering RS</em></strong><br />
se base les la similarité entre le comportement des utilisateurs afin de faire des recommandations.<br />
Par exemple, si Thomas et George ont des goûts très similaires, et que Thomas aime le livre A, il est très probable que George aime aussi le livre A.</li>
</ul>
</div>
<div id="hybrid" class="section level2">
<h2>Hybrid</h2>
<p>Les approches hybrides des <em><strong>S.R.</strong></em> tentent d’utiliser une combinaison des approches vues précédement afin d’avoir les bénéfices de chaque approche.<br />
Il y a également des méthodes incluant le contexte dans lequel est l’utilisateur afin de produire la recommandation. (contexte temporel par exemple)<br />
Ce sont des méthodes plus avancées qu’on ne couvrira pas plus en détails dans ce rapport.</p>
</div>
<div id="sources-de-données" class="section level2">
<h2>Sources de données :</h2>
<p>Il existe trois sources de données traditionnellement utilisées dans les <em><strong>S.R.</strong></em>.</p>
<ol style="list-style-type: decimal">
<li>Item :<br />
Sont les objets à être recommandés : Films, articles, pages web, etc…<br />
Peuvent avoir différents attributs selon la tâche de recommandation voulue (Genre, avteur, résumé, etc…).<br />
</li>
<li>Utilisateur :<br />
Une multitude de de données peuvent être recueillies sur les utilisateurs, dépendamment du type de <em><strong>S.R.</strong></em> qu’on veut mettre en place : Avis, notes, données démographiques, historique de navigation, historique de recherche, réseau, etc…<br />
Ces données constituent le modèle d’utilisateur utilisé dans le <em><strong>S.R.</strong></em> et constituent un élément très important pour la personnalisation des recommandations.<br />
</li>
<li>Transaction<br />
Constitue une intéraction entre l’utilisateur et le <em><strong>S.R.</strong></em>. Cet historique d’intéractions devient une source importante de données pour le <em><strong>S.R.</strong></em>.<br />
Ces intéractions peuvent être de type <em>explicite</em> (Rating numérique, satisfaction sur une échelle, Like, binaire/oui/non, etc…) ou <em>implicite</em> (Termes de recherche, Click, historique de navigation, etc…).</li>
</ol>
</div>
</div>
<div id="méthodes-dapprentissage-machine-utilisées" class="section level1">
<h1>Méthodes d’apprentissage machine utilisées</h1>
<p>Cette section a pour but d’informer son lecteur sur les différentes approches utilisées en apprentissage machines pour les systèmes de recommandations. Tel que mentionné dans <em><strong></strong></em>, il faut d’abord traiter les données avant de pouvoir les utiliser dans nos modèles d’apprentissage. D’abord, différentes méthodes de pré-traitement sont proposées. Ensuite, il sera question des algortihmes utilisés pour les différentes approches d’apprentisage machine répertoriées par <em><strong></strong></em>. Des références sont proprosées afin de fournir des ressources supplémentaires à la compréhension des méthodes.</p>
<div id="pré-traitement-des-données" class="section level2">
<h2>Pré-traitement des données</h2>
<div id="mesures-de-similarités" class="section level3">
<h3>Mesures de similarités</h3>
<p>Plusieurs méthodes requièrent de pouvoir mesurer la similarité entre les individus. Pour ce faire, différentes mesures de similarités sont utilisées. <em><strong></strong></em> propose différentes mesure de distance tel que la distance euclidienne, la “similarité cosine” et la corrélation pearson. D’autres mesures de distance sont proposés et testés dans
<em><strong></strong></em>. Dans leur contexte, ils ont trouvé que la mesure de similarité n’améliorait pas la performance comparativement à une méthode aléatoire.</p>
</div>
<div id="échantillonage" class="section level3">
<h3>Échantillonage</h3>
<p>Il est important que les échantillons représentent bien les données originales. Ainsi, le choix des observations dans nos échantillons doit se faire de façon aléatoire. Plusieurs méthodes d’échantillonage existe, la plus classique étant l’échantillonage aléatoire simple. Cela consiste à ce que toutes les observations aient une probabilité égal de se retrouver dans l’un des échantillons. D’autres méthodes existent et peuvent être utilisés. Par exemple, lorsqu’il y a présence de classes rares<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>. Cette revue <em><strong></strong></em> propose une méthode pour palier à ce problème. <em><strong></strong></em> évalue dix différentes méthodes de sous et de sur-échantillonage.</p>
<p>Généralement, il faut diviser nos données afin d’avoir un échantillon d’entraînement et de test. On ajuste un modèle sur l’échantillon d’entraînement et on évalue ensuite la performance de ce modèle sur l’échantillon test. Cependant, comme le fait mention <em><strong></strong></em>, il faudra diviser l’échantillon en trois: entraînement, validation et test. “L’échantillon d’entraînement sert à ajuster le modèle, l’échantillon de validation sert à ajuster les hyperparamètres et le test sert à évaluer le modèle”. <em><strong></strong></em> Il est à noter que l’échantillon test est divisé en “known” et “unknown” data. Les données connu dans l’échantillon test permettent de faire des recommendations et on évalue ensuite les recommendations grâce aux données “inconnus”. La validation-croisé peut aussi être utilisé.</p>
<p>L’échantillonage est une technique répandu et une des plus importantes dans le contexte de “Data Mining”. Effectivement, cela permet d’avoir un sous-ensemble représentatif des données disponibles lorsqu’il est sélectionné de façon aléatoire. De plus, il est possible de diviser les données de façon à avoir un échantillon d’entraînement, de validation et test. Cela permet d’entraîner des modèles, d’évaluer leurs performances et de calculer la performance sans biais du meilleur modèle.</p>
</div>
<div id="réduction-de-la-dimension" class="section level3">
<h3>Réduction de la dimension</h3>
<p>Les techniques de réduction de dimensions permettent de régler deux problèmes rencontrés dans les bases de données; les matrices creuses(sparse matrix) et un grand nombre de prédicteurs.</p>
<div id="pca" class="section level4">
<h4>PCA</h4>
<p>L’analyse en composante principale utilise les vecteurs et valeurs propres afin d’obtenir une nouvelle matrice où chaque colonne est une combinaison linéaires des prédicteurs. Pour ce faire, il faut utiliser la matrice de variance-covariance. Il est recommandé de standardisé les données avant d’obtenir la matrice de variance-covariance afin de mettre les données sur la même échelle. Une fois notre nouvelle matrice de composantes principales créée, il faut ensuite choisir les composantes qui permettent d’expliquer le plus de variance dans les données. Le chapitre 10.2 de <em><strong></strong></em> offre les détails de cette méthode.</p>
</div>
<div id="svd" class="section level4">
<h4>SVD</h4>
<p>La décomposition à valeur singulière (Single Value Decomposition) est une méthode de factorisation matricielle permettant de réduire la dimension d’une matrice. Cette méthode peut être utilisé dans le PCA. Cela permet de trouver les composantes principales sans passer par la matrice de variance-covariance. Cette <link><a href="https://www.youtube.com/watch?v=UyAfmAZU_WI"><strong><em></em></strong></a> sur youtube, , permet de bien comprendre l’intuition derrière le SVD. Cet article, <em><strong></strong></em>, portant sur l’analyse de gènes, offre aussi une bonne explication sur le PCA et le SVD, ainsi que leurs différences.</p>
</div>
</div>
</div>
<div id="méthodes-supervisées" class="section level2">
<h2>Méthodes supervisées</h2>
<p>Afin de faire de la classification, il est possible d’utiliser des algorithmes populaires d’apprentisage supervisé. Parmi ces algorithmes, on peut compter le kNN, l’arbre de décision, les forêt aléatoire, la régression logistique, les SVM, les réseaux de neuronnes artificiels et des méthodes d’ensemble dont les plus populaires sont le bagging et le boosting. Ces méthodes et autres sont proposées et expliquées dans <em><strong></strong></em>. Certaines ressources et revues littéraires sont mis de l’avant par l’auteur afin d’encourager le lecteur à avoir une meilleure compréhension de ces méthodes. <em><strong></strong></em> offre une introduction à la majorité des méthodes énumérés ci-haut. Il procure aussi des exemples avec R afin de mettre ces méthodes en place.</p>
</div>
<div id="méthodes-non-supervisés" class="section level2">
<h2>Méthodes non-supervisés</h2>
<div id="analyse-de-regroupement" class="section level3">
<h3>Analyse de regroupement</h3>
<p>Il existe deux grandes catégories d’algorithme de regroupement;soit les méthodes de partition et les méthodes hiérarchiques. Ces méthodes utilisent les mesures de similarités discutées plus haut. Il faut essayer différents algorithmes puisqu’ils agissent différemment face à la structure des observations. Une des méthodes les plus connue est le k-means. Il consiste à regrouper les observations similaires autour de n centroïdes en calculant la distance qui les séparent. Plusieurs autres algorithmes existent tels que le regroupement hiérarchique, DBSCAN <em><strong></strong></em> et autres._<strong></strong>_ Il est à noter que certaines de ces méthodes utilisent des heuristiques et ne convergent pas à la solution optimale. Se reférer à <link><a href="https://www.youtube.com/watch?v=HtSuA80QTyo&amp;list=PLUl4u3cNGP61Oq3tWYp6V_F-5jb5L2iHb"><strong><em></em></strong></a> afin d’avoir une introduction à l’algorithmique.</p>
</div>
<div id="règles-dassociations" class="section level3">
<h3>Règles d’associations</h3>
<p>Les règles d’association sont une méthode qui cherchent des patterns dans les données afin d’identifier les observations qui se ressemblent et qui se présentent ensemble. Par exemple, si on a plusieurs utilisateurs avec des paniers de “films”, il est possible d’identifier la fréquence à laquelle deux films se retrouvent dans les “paniers” des utilisateurs. Comme il est mentionné dans <em><strong></strong></em>, “les règles tels que 90% des utilisateurs aimant l’article A &amp; B aiment aussi l’article C, 30% aiment tous les articles” sont très utile dans les systèmes de recommandation. Cet article, <em><strong></strong></em>, présente aussi un algorithme alternatif à l’algorithme “Apriori” afin de générer des règles d’associations tels que la fréquence, support, confiance et le lift. Contrairement à l’algorithme “Apriori”, l’avantage est qu’il n’est pas nécessaire de spécifier un support minimum. Ces papiers proposent des méthodes et des cas utilisant les règles d’association dans les systèmes de recommandation; <em><strong></strong></em>, <em><strong></strong></em> et <em><strong></strong></em>.</p>
</div>
</div>
<div id="application" class="section level2">
<h2>Application</h2>
<p>Le lecteur est invité à consulter le tableau “Classification of Recommender Systems Research” dans <em><strong></strong></em> afin de connaître les techniques les plus utilisés pour les systèmes “content-based”, “collaboratif” et “hybride”.</p>
</div>
</div>
<div id="évaluation" class="section level1">
<h1>Évaluation</h1>
<p>Différentes méthodes d’évaluation existe pour les systèmes de recommendation. Normalement, les modèles sont évalués en utilisant les prédictions faites sur l’échantillon test et il est ainsi possible d’avoir une métrique de performance tel que le taux de bonne classification. Cependant, dans le contexte d’un système de recommendation, il faut aussi tenir compte d’autres facteurs. Tel que mentionné dans <em><strong></strong></em>, la découverte de nouveaux items, la diversité des items et même la rapidité du système peuvent être utilisé pour l’évaluation. De ce fait, il est aussi possible d’évaluer un système de recommendation en le testant sur un petit groupe d’utilisateurs afin de savoir s’il répond aux besoins des utilisateurs. On propose ainsi trois différentes façon d’évaluer un système de recommandation; approche classique, étude sur les utilisateurs et expérimentation en ligne. Le lecteur est invité à consulter <em><strong></strong></em> afin d’avoir plus d’informations sur les différentes approches. Seul l’approche classique sera abordé brièvement ici. C’est aussi cette méthode qui sera utilisé dans le tutoriel.</p>
<p>L’approche classique est l’approche avec laquelle on évalue la performance du modèle sur l’échantillon test. Ces mesures de performances peuvent être variés. Dans le cas d’une classification, la précision, le AUC ou le ROC peuvent être utilisé. Cette article <em><strong></strong></em> utilise aussi des tests afin de comparer des modèles de classifications entre eux. Ces tests diffèrent selon la structure des échantillons utilisés, soit apparié ou indépendant. De plus, des mesures de distance peuvent être utilisés selon le contexte de prédiction. Les indices de performance les plus utilisés sont le RMSE, le MAE ou le MAPE. D’autres mesures existe aussi dans un contexte de classement ordonné. Plus d’informations sont disponible à <em><strong></strong></em>.</p>
</div>
<div id="revue-des-ressources-r" class="section level1">
<h1>Revue des ressources R</h1>
<div id="livres-pratiques" class="section level2">
<h2>Livres pratiques</h2>
<p>Voici quelques livres pratiques sur l’implémentation des <em><strong>S.R.</strong></em> en R et Python (Disponibles gratuitement à travers la bibliothèque de HEC - <link><a href="https://www.hec.ca/biblio/banques-de-donnees/oreilly.html"><strong><em></em></strong></a>) :</p>
<ul>
<li>Building a Recommendation System with R (<link><a href="https://learning.oreilly.com/library/view/building-a-recommendation/9781783554492/"><strong><em></em></strong></a>)<br />
</li>
<li>Hands-On Recommendation Systems with Python (<link><a href="https://learning.oreilly.com/library/view/hands-on-recommendation-systems/9781788993753/"><strong><em></em></strong></a>)<br />
</li>
<li>Practical Recommender Systems (<link><a href="https://learning.oreilly.com/library/view/practical-recommender-systems/9781617292705/"><strong><em></em></strong></a>)</li>
</ul>
</div>
<div id="bases-de-données" class="section level2">
<h2>Bases de données</h2>
<p>Il y a plusieurs données libres d’accès disponibles sur internet qui sont utilisées pour les <em><strong>S.R.</strong></em>. Voici deux liens où vous pourrez trouver plusieurs datasets :</p>
<ul>
<li><em>9 Must-Have Datasets for Investigating Recommender Systems</em>. (<link><a href="https://www.kdnuggets.com/2016/02/nine-datasets-investigating-recommender-systems.html"><strong><em></em></strong></a>)</li>
<li><em>Public Datasets For Recommender Systems</em>. (<link><a href="https://github.com/caserec/Datasets-for-Recommender-Systems"><strong><em></em></strong></a>)</li>
</ul>
<p>Plusieurs de ces datasets sont accessibles à travers divers librairies dédiées aux <em><strong>S.R.</strong></em>, comme on le verra dans les prochaines sections.</p>
</div>
<div id="librairies" class="section level2">
<h2>Librairies</h2>
<p>Il existe quatres principales <a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> librairies sur R afin de créer des <em><strong>S.R.</strong></em>, que nous présentons brièvement dans cette section. On détaillera par la suite les fonctionnalité d’une de ces quatres librairies à travers un exemple concrêt.</p>
<div id="package-rrecsys" class="section level3">
<h3>Package : <code>rrecsys</code></h3>
<p>Voici la description officielle <a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> de la librairie :</p>
<hr />
<blockquote>
<p><em></em>.<br />
<em></em></p>
</blockquote>
<blockquote>

</blockquote>
<blockquote>
<p><em></em></p>
</blockquote>
<blockquote>

</blockquote>
<hr />
<p>Voici des ressources pour prendre en main la librairie :</p>
<ul>
<li>Page <code>CRAN</code> oficielle de la librairie : (<link><a href="https://cran.r-project.org/web/packages/rrecsys/index.html"><strong><em></em></strong></a>)</li>
<li>Dépôt <code>Github</code> oficielle de la librairie : (<link><a href="https://github.com/ludovikcoba/rrecsys"><strong><em></em></strong></a>)</li>
<li>PDF de la documentation de la librairie (via <code>CRAN</code>): (<link><a href="https://cran.r-project.org/web/packages/rrecsys/rrecsys.pdf"><strong><em></em></strong></a>)</li>
</ul>
</div>
<div id="package-recosystem" class="section level3">
<h3>Package : <code>recosystem</code></h3>
<p>Voici la description officielle <a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> de la librairie :</p>
<hr />
<blockquote>
<p><em></em>. <strong>(<link><a href="http://www.csie.ntu.edu.tw/~cjlin/libmf/"><strong><em></em></strong></a>)</strong></p>
</blockquote>
<blockquote>
<p><em></em>.</p>
</blockquote>
<blockquote>
<p><em></em>.</p>
</blockquote>
<hr />
<p>Voici des ressources pour prendre en main la librairie :</p>
<ul>
<li>Page <code>CRAN</code> oficielle de la librairie : (<link><a href="https://cran.r-project.org/web/packages/recosystem/index.html"><strong><em></em></strong></a>)</li>
<li>Dépôt <code>Github</code> oficielle de la librairie : (<link><a href="https://github.com/yixuan/recosystem"><strong><em></em></strong></a>)</li>
<li>PDF de la documentation de la librairie (via <code>CRAN</code>): (<link><a href="https://cran.r-project.org/web/packages/recosystem/recosystem.pdf"><strong><em></em></strong></a>)</li>
<li>Site web de la librairie <code>LIBMF</code> sur laquelle est basée la librairie <code>recosystem</code>: (<link><a href="https://www.csie.ntu.edu.tw/~cjlin/libmf/"><strong><em></em></strong></a>)</li>
<li>Dépôt <code>Github</code> oficielle de la librairie <code>LIBMF</code>: (<link><a href="https://github.com/cjlin1/libmf"><strong><em></em></strong></a>)</li>
</ul>
</div>
<div id="package-rectools" class="section level3">
<h3>Package : <code>rectools</code></h3>
<p>Voici la description officielle tirée du dépôt <code>Github</code> <a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> de la librairie :</p>
<hr />
<blockquote>
<p><br />
</p>
</blockquote>
<blockquote>

</blockquote>
<hr />
<p>Voici des ressources pour prendre en main la librairie :</p>
<ul>
<li>Dépôt <code>Github</code> oficielle de la librairie : (<link><a href="https://github.com/Pooja-Rajkumar/rectools"><strong><em></em></strong></a>)</li>
<li>Présentation de la librairie (format <strong>Powerpoint</strong>): (<link><a href="http://heather.cs.ucdavis.edu/BARUG.pdf"><strong><em></em></strong></a>)</li>
</ul>
<p><strong><em>Note</em></strong><br />
Ce package n’est pas disponible sur <code>CRAN</code>. D’après le document de présentation des auteurs, qui date du <code>'2016-12-13'</code>, il est indiqué à propos du package: <strong>“soon to be submitted to CRAN”</strong>.</p>
</div>
<div id="package-recommenderlab" class="section level3">
<h3>Package : <code>recommenderlab</code></h3>
<p>Voici la description officielle <a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a> de la librairie :</p>
<hr />
<blockquote>
<p><em></em></p>
</blockquote>
<blockquote>

</blockquote>
<blockquote>
<p><em></em></p>
</blockquote>
<blockquote>

</blockquote>
<blockquote>
<em></em><br />

</blockquote>
<hr />
<p>Voici des ressources pour prendre en main la librairie :</p>
<ul>
<li>Page <code>CRAN</code> oficielle de la librairie : (<link><a href="https://cran.r-project.org/"><strong><em></em></strong></a>)</li>
<li>Dépôt <code>Github</code> oficielle de la librairie : (<link><a href="https://github.com/mhahsler/recommenderlab"><strong><em></em></strong></a>)</li>
<li>PDF de la documentation de la librairie (via <code>CRAN</code>): (<link><a href="https://cran.r-project.org/web/packages/recommenderlab/recommenderlab.pdf"><strong><em></em></strong></a>)</li>
<li>Document de présentation officiel des fonctionnalités du package (via <code>CRAN</code>): (<link><a href="https://cran.r-project.org/web/packages/recommenderlab/vignettes/recommenderlab.pdf"><strong><em></em></strong></a>)</li>
<li>Guide pratique (présenté plus haut) sur les <em><strong>S.R.</strong></em> se basant sur cette librairie:<br />
Building a Recommendation System with R (<link><a href="https://learning.oreilly.com/library/view/building-a-recommendation/9781783554492/"><strong><em></em></strong></a>)</li>
</ul>
</div>
</div>
</div>
<div id="application-pratique" class="section level1">
<h1>Application pratique</h1>
<p>Dans cette section, on va explorer le package  à travers la mise en place d’un <em><strong>S.R.</strong></em> sur des données disponibles dans le package.</p>
<p>À noter qu’on s’est inspiré de la documentation du package, de ressources en ligne et des exemples fournis dans le guide pratique suivant: <em>Building a Recommendation System with R - <link><a href="https://learning.oreilly.com/library/view/building-a-recommendation/9781783554492/"><strong><em></em></strong></a>)</em></p>
<p><strong><em>Librairies utilisées</em></strong></p>
<pre class="r"><code># Pour la reproductibilité de l&#39;exemple :
set.seed(2020)
## Installer packages si ce n&#39;est pas déjà fait :
# install.packages(&quot;recommenderlab&quot;)
# install.packages(&quot;ggplot2&quot;)
library(&quot;recommenderlab&quot;)
library(&quot;ggplot2&quot;)
## On peut appeler la documentation du package aussi :
??recommenderlab</code></pre>
<div id="données-disponibles-dans-recommenderlab" class="section level2">
<h2>Données disponibles dans <code>recommenderlab</code></h2>
<p>Il y a plusieurs jeux de données disponibles dans la librairie.<br />
Voici comment on peut chercher ces données.</p>
<pre class="r"><code>data_package &lt;- data(package = &quot;recommenderlab&quot;)
available.data &lt;- data_package$results[, c(&quot;Title&quot;,&quot;Item&quot;)]
# On peut les voir sous forme de tableau avec knit::kable (Rmarkdown)
knitr::kable(available.data, caption = &quot;Available data in recommenderlab&quot;)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-3">Table 2: </span>Available data in recommenderlab</caption>
<thead>
<tr class="header">
<th align="left">Title</th>
<th align="left">Item</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Jester dataset (5k sample)</td>
<td align="left">Jester5k</td>
</tr>
<tr class="even">
<td align="left">Jester dataset (5k sample)</td>
<td align="left">JesterJokes (Jester5k)</td>
</tr>
<tr class="odd">
<td align="left">Anonymous web data from www.microsoft.com</td>
<td align="left">MSWeb</td>
</tr>
<tr class="even">
<td align="left">MovieLense Dataset (100k)</td>
<td align="left">MovieLense</td>
</tr>
<tr class="odd">
<td align="left">MovieLense Dataset (100k)</td>
<td align="left">MovieLenseMeta (MovieLense)</td>
</tr>
</tbody>
</table>
<pre class="r"><code># On peut faire appel à la documentation pour chaque jeux de données
?MovieLense</code></pre>
<p> <br />
Le jeux de données qu’on va utiliser est celui de .<br />
Voici la description disponible sur le jeux de données dans la documentation :</p>
<hr />
<blockquote>
<p><em></em></p>
</blockquote>
<hr />
</div>
<div id="quelques-fonctions-du-package-recommenderlab" class="section level2">
<h2>Quelques fonctions du package <code>recommenderlab</code></h2>
<p>Nous allons explorer les données, tout en utilisant les fonctions disponibles dans le package .</p>
<p>La fonction  permet d’importer le jeux de données.</p>
<pre class="r"><code>data(MovieLense)</code></pre>
<hr />
<p>On peut voir que notre matrice contient 943 utilisateurs et 1664 films.</p>
<pre class="r"><code>MovieLense</code></pre>
<pre><code>943 x 1664 rating matrix of class &#39;realRatingMatrix&#39; with 99392 ratings.</code></pre>
<hr />
<p> <br />
On peut voir la classe de l’objet MovieLense</p>
<pre class="r"><code>class(MovieLense)</code></pre>
<pre><code>[1] &quot;realRatingMatrix&quot;
attr(,&quot;package&quot;)
[1] &quot;recommenderlab&quot;</code></pre>
<p> <br />
On peut voir dans la documentation quel type d’objet est <code>"realRatingMatrix"</code> avec le code .</p>
<p>Voici la description des objets <code>"realRatingMatrix"</code> disponible dans la documentation :</p>
<hr />
<blockquote>
<p><em></em></p>
</blockquote>
<hr />
<p> <br />
On peut voir l’utilité de cet encodage par rapport à une matrice normale qui prendrait 9 fois plus d’espace.</p>
<pre class="r"><code>object.size(MovieLense)</code></pre>
<pre><code>1409432 bytes</code></pre>
<pre class="r"><code>object.size(as(MovieLense, &quot;matrix&quot;))</code></pre>
<pre><code>12761360 bytes</code></pre>
<pre class="r"><code>as.numeric(round(object.size(as(MovieLense, &quot;matrix&quot;)) / 
                   object.size(MovieLense),2))</code></pre>
<pre><code>[1] 9.05</code></pre>
<hr />
<p>On peut également voir les méthodes qu’on peut appliquer sur cet objet.</p>
<pre class="r"><code>methods(class = class(MovieLense))</code></pre>
<pre><code> [1] [                      [&lt;-                    binarize              
 [4] calcPredictionAccuracy coerce                 colCounts             
 [7] colMeans               colSds                 colSums               
[10] denormalize            dim                    dimnames              
[13] dimnames&lt;-             dissimilarity          evaluationScheme      
[16] getData.frame          getList                getNormalize          
[19] getRatingMatrix        getRatings             getTopNLists          
[22] image                  normalize              nratings              
[25] Recommender            removeKnownRatings     rowCounts             
[28] rowMeans               rowSds                 rowSums               
[31] sample                 show                   similarity            
see &#39;?methods&#39; for accessing help and source code</code></pre>
<pre class="r"><code># On peut utiliser la fonction d&#39;aide pour chaque 
# élément afin d&#39;avoir sa documentation. Par ex:
# ?binarize</code></pre>
<hr />
<p> <br />
 nous permet d’avoir le nom des utilisateurs (<em>dimension [1]</em>) et le nom des différents films (<em>dimension [2]</em>) dans le jeu de donnée.</p>
<pre class="r"><code>dimnames(MovieLense[1:5,1:5])</code></pre>
<pre><code>[[1]]
[1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot;

[[2]]
[1] &quot;Toy Story (1995)&quot;  &quot;GoldenEye (1995)&quot;  &quot;Four Rooms (1995)&quot;
[4] &quot;Get Shorty (1995)&quot; &quot;Copycat (1995)&quot;   </code></pre>
<hr />
<p> <br />
 permet d’avoir les évaluations (ratings) sous la forme d’un vecteur numérique.</p>
<pre class="r"><code>getRatings(MovieLense)[1:5]</code></pre>
<pre><code>[1] 5 4 4 4 4</code></pre>
<hr />
<p> <br />
 permet d’avoir les données sous forme matricielle.</p>
<pre class="r"><code>getRatingMatrix(MovieLense)[1:3,1:3]</code></pre>
<pre><code>3 x 3 sparse Matrix of class &quot;dgCMatrix&quot;
  Toy Story (1995) GoldenEye (1995) Four Rooms (1995)
1                5                3                 4
2                4                .                 .
3                .                .                 .</code></pre>
<hr />
<p> <br />
On peut aussi passer par la fonction  pour convertir les données dans un autre format.</p>
<pre class="r"><code>as(MovieLense, &quot;data.frame&quot;)[1:3,1:3]</code></pre>
<pre><code>    user              item rating
1      1  Toy Story (1995)      5
453    1  GoldenEye (1995)      3
584    1 Four Rooms (1995)      4</code></pre>
<pre class="r"><code>as(MovieLense, &quot;list&quot;)[[1]][1:3]</code></pre>
<pre><code> Toy Story (1995)  GoldenEye (1995) Four Rooms (1995) 
                5                 3                 4 </code></pre>
<hr />
<p> <br />
Il est égaelement possible de convertir différents objets en <code>"realRatingMatrix"</code>.</p>
<pre class="r"><code>MovieLenseDF=as(MovieLense, &quot;data.frame&quot;)
as(MovieLenseDF, &quot;realRatingMatrix&quot;)</code></pre>
<pre><code>943 x 1664 rating matrix of class &#39;realRatingMatrix&#39; with 99392 ratings.</code></pre>
<hr />
<p> <br />
Les fonctions , , , , ,  permettent des calculs agrégés comme leurs noms l’indique.<br />
Leur spécificité est qu’ils sont applicables à des objets <code>"realRatingMatrix"</code>, contrairement aux méthodes normales.</p>
<pre class="r"><code># ratings moyens reçus par les 3 premiers films
colMeans(MovieLense[,1:3]) </code></pre>
<pre><code> Toy Story (1995)  GoldenEye (1995) Four Rooms (1995) 
         3.878319          3.206107          3.033333 </code></pre>
<pre class="r"><code># ratings moyens donnés par les 3 premiers utilisateurs
rowMeans(MovieLense[1:3,]) </code></pre>
<pre><code>       1        2        3 
3.605166 3.704918 2.764706 </code></pre>
</div>
<div id="exploration-des-données-movielense" class="section level2">
<h2>Exploration des données <code>MovieLense</code></h2>
<p>Afin d’analyser les données, nous préférons utiliser un dataframe.<br />
On commence par analyser la structure des <code>ratings</code>.</p>
<pre class="r"><code>table(MovieLenseDF$rating, dnn = c(&quot;Fréquence des ratings&quot;))</code></pre>
<pre><code>Fréquence des ratings
    1     2     3     4     5 
 6059 11307 27002 33947 21077 </code></pre>
<hr />
<p> <br />
On peut visualiser la matrice aussi avec la fonction  du package.<br />
On peut avoir une plus belle visualisation que celle proposée, en utilisant le package .</p>
<pre class="r"><code>## Fonction du package
image(MovieLense[1:100,1:100])
# Utilisation de ggplot2
df=as(MovieLense[1:100,1:100], &quot;data.frame&quot;)

ggplot(df, aes(item,user, fill=rating)) + 
    geom_tile() +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())+
  labs(x=&quot;Movies&quot;,y=&quot;Users&quot;, title = &quot;GGplot2&quot;)</code></pre>
<div class="columns">
<div class="column" style="width:49%;">
<p><img src="/post/Rapport_Session_files/figure-html/unnamed-chunk-17-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div><div class="column" style="width:2%;">
<p> 
<!-- an empty Div (with a whitespace), serving as
a column separator --></p>
</div><div class="column" style="width:49%;">
<p><img src="/post/Rapport_Session_files/figure-html/unnamed-chunk-18-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
</div>
<hr />
<p>On peut visualiser la distribution des <code>ratings</code> moyens, autant au niveau des utilisateurs que des films.</p>
<pre class="r"><code># Voici le code pour sortir le premier histogramme, à titre d&#39;exemple :
# Hist. pour la distribution des évaluations moyennes des utilisateur
qplot(rowMeans(MovieLense), colour = I(&quot;#3B444B&quot;),
      fill=I(&quot;#5D8AA8&quot;), alpha=I(.2)) +
  labs(x=&quot;Rating&quot;,y=&quot;Count&quot;, 
       title=&quot;Distribution des évaluations moyennes des utilisateur&quot;)+
  geom_vline(
    aes(xintercept = mean(rowMeans(MovieLense))),col=&#39;#3B444B&#39;,size=0.5)+
  geom_text(
    aes(label=paste(&quot;Évaluation moyenne\ndes utilisateur =&quot;,
                    round(mean(rowMeans(MovieLense)),2)),
    y=110,x=mean(rowMeans(MovieLense))-0.5))+
  theme_classic()</code></pre>
<div class="columns">
<div class="column" style="width:49%;">
<p><img src="/post/Rapport_Session_files/figure-html/unnamed-chunk-20-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div><div class="column" style="width:2%;">
<p> 
<!-- an empty Div (with a whitespace), serving as
a column separator --></p>
</div><div class="column" style="width:49%;">
<p><img src="/post/Rapport_Session_files/figure-html/unnamed-chunk-21-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
</div>
<p>On peut aussi voir la distribution du nombre de <code>ratings</code>.</p>
<div class="columns">
<div class="column" style="width:49%;">
<p><img src="/post/Rapport_Session_files/figure-html/unnamed-chunk-22-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div><div class="column" style="width:2%;">
<p> 
<!-- an empty Div (with a whitespace), serving as
a column separator --></p>
</div><div class="column" style="width:49%;">
<p><img src="/post/Rapport_Session_files/figure-html/unnamed-chunk-23-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
</div>
<hr />
<p>On peut chercher les films ayant la plus haute et la plus basse moyenne d’évaluations.<br />
On peut voir que ces films ont reçus très peu d’évaluations.</p>
<pre class="r"><code>eval_moy_par_film = colMeans(MovieLense)
# top 5 plus haut rating moyen
top5 = head(eval_moy_par_film[order(eval_moy_par_film, 
                                    decreasing = TRUE)], 5) 
top5 = cbind(top5,colCounts(MovieLense)[names(top5)])
colnames(top5)=c(&quot;Rating moyen&quot;, &quot;Nombre de rating&quot;)
top5</code></pre>
<pre><code>                                           Rating moyen Nombre de rating
Great Day in Harlem, A (1994)                         5                1
They Made Me a Criminal (1939)                        5                1
Prefontaine (1997)                                    5                3
Marlene Dietrich: Shadow and Light (1996)             5                1
Star Kid (1997)                                       5                3</code></pre>
<pre class="r"><code># top 5 plus bas rating moyen
last5 = tail(eval_moy_par_film[order(eval_moy_par_film, 
                                     decreasing = TRUE)], 5)
last5 = cbind(last5,colCounts(MovieLense)[names(last5)])
colnames(last5)=c(&quot;Rating moyen&quot;, &quot;Nombre de rating&quot;)
last5</code></pre>
<pre><code>                                           Rating moyen Nombre de rating
Nobody Loves Me (Keiner liebt mich) (1994)            1                1
Getting Away With Murder (1996)                       1                1
New Age, The (1994)                                   1                1
Further Gesture, A (1996)                             1                1
Mat&#39; i syn (1997)                                     1                1</code></pre>
<hr />
<p>Dans la section suivante, on passe en revue quelques étapes intéressantes de la préparation des données nécessaires pour leur utilisation dans les <em><strong>S.R.</strong></em>.</p>
</div>
<div id="traitement-des-données" class="section level2">
<h2>Traitement des données</h2>
<p>Une fois l’exploration des données faites, il faut traiter les données. D’abord, on a observé peu d’évaluations faites pour certains films et utilisateurs. Ainsi, on détermine un seuil minimale d’évaluations pour les différents films et utilisateurs.<br />
Afin d’optimiser le modèle, il sera possible de revenir changer ces “paramètres”.</p>
<pre class="r"><code>data_for_system &lt;- MovieLense[rowCounts(MovieLense) &gt; 50, 
                              colCounts(MovieLense) &gt;75]
data_for_system </code></pre>
<pre><code>560 x 434 rating matrix of class &#39;realRatingMatrix&#39; with 63467 ratings.</code></pre>
<pre class="r"><code>min_utilisateur = min(rowCounts(data_for_system))
max_utilisateur = max(rowCounts(data_for_system))
min_film = min(colCounts(data_for_system))
max_film = max(colCounts(data_for_system))
utilisateur &lt;- cbind(min_utilisateur,max_utilisateur)
film &lt;- cbind(min_film,max_film)
eval_min_max &lt;- rbind(utilisateur,film)
colnames(eval_min_max) &lt;- c(&#39;Min&#39;,&#39;Max&#39;)
rownames(eval_min_max) &lt;-c(&#39;Évaluation par utilisateur&#39;,
                &#39;Évaluation par film&#39;)
eval_min_max</code></pre>
<pre><code>                           Min Max
Évaluation par utilisateur  27 331
Évaluation par film         47 456</code></pre>
<hr />
<p> <br />
On peut aussi utiliser la fonction image afin d’avoir une visualisation pour les utilisateurs ayant fait le plus d’évaluations et les films ayant reçu le plus d’évaluations.</p>
<pre class="r"><code>image(data_for_system[rowCounts(data_for_system) &gt; 
                        quantile(rowCounts(data_for_system),0.95), 
                      colCounts(data_for_system) &gt; 
                        quantile(colCounts(data_for_system),0.95)])</code></pre>
<p><img src="/post/Rapport_Session_files/figure-html/unnamed-chunk-26-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>On remarque, à la colonne 2 par exemple, que les évaluations pour un film sont très différentes selon les utilisateurs. Afin de prendre en considération le fait qu’un utilisateur peut donner en moyenne des évaluations plus basse ou plus élevé, on peut standardisé les données.<br />
La fonction  de la librairie va nous aider.<br />
Par défaut, la normalisation se fait sur chaque rangée. Il est possible de changer le paramètre row à  afin de normaliser sur les colonnes, si nécessaires.<br />
Aussi, la fonction utilise la méthode centrer. “Z-score” peut aussi être utilisé.</p>
<pre class="r"><code>data_for_system_norm &lt;- normalize(data_for_system) 
data_for_system_norm_z &lt;- normalize(data_for_system, 
                                    method = &quot;Z-score&quot;) 
##Utilise Z-score Lorsque les données sont normalisées, 
# la heatmap résultante se colorie.
# Nous n&#39;avons pas trouvé de paramètres pour contrôler 
# la couleur de la fonction. Les paramètres par default 
# se chargent selon les cas..
image(data_for_system_norm[rowCounts(data_for_system_norm) &gt; 
                             quantile(rowCounts(data_for_system_norm),0.95), 
                      colCounts(data_for_system_norm) &gt; 
                        quantile(colCounts(data_for_system_norm),0.95)])</code></pre>
<p><img src="/post/Rapport_Session_files/figure-html/unnamed-chunk-27-1.png" width="60%" style="display: block; margin: auto;" />
***</p>
<p>Si les besoins sont nécessaires, il est aussi possible de “dénormaliser” les données. La fonction denormalize() permet cela.</p>
<pre class="r"><code>data_for_system_norm_denorm &lt;- denormalize(data_for_system_norm)
getRatingMatrix(data_for_system_norm_denorm)[1:4,1:4]</code></pre>
<pre><code>4 x 4 sparse Matrix of class &quot;dgCMatrix&quot;
  Toy Story (1995) GoldenEye (1995) Four Rooms (1995) Get Shorty (1995)
1                5                3                 4                 3
2                4                .                 .                 .
3                .                .                 .                 .
5                4                3                 .                 .</code></pre>
</div>
<div id="calcul-de-la-similarité" class="section level2">
<h2>Calcul de la similarité</h2>
<p>L’utilisation d’une mesure de similarité prend une grande place dans les <em><strong>S.R.</strong></em> à fitrage collaboratifs. Dans cette section, on va faire la démonstration de ces méthodes en utilisant le package .</p>
<p> offre la fonction .</p>
<pre class="r"><code># En utilisant la documentation :
?similarity</code></pre>
<p>Voici ce qu’on peut lire dans la documentation de la fonction :</p>
<hr />
<blockquote>
<p><em></em></p>
</blockquote>
<blockquote>
<p><em></em></p>
</blockquote>
<blockquote>
<p><em></em></p>
</blockquote>
<blockquote>
<p><em></em></p>
</blockquote>
<p>Les arguments importants sont les suivants :</p>
<blockquote>
<p><em></em></p>
</blockquote>
<blockquote>
<p><em></em></p>
</blockquote>
<hr />
<p> 
On peut calculer la similarité des 3 premiers films et explorer le résultat.</p>
<pre class="r"><code>similarity_movies &lt;- similarity(MovieLense[,1:3], 
                               method = &quot;cosine&quot;, which = &quot;items&quot;)
as.matrix(similarity_movies)</code></pre>
<pre><code>                  Toy Story (1995) GoldenEye (1995) Four Rooms (1995)
Toy Story (1995)         0.0000000        0.9487374         0.9132997
GoldenEye (1995)         0.9487374        0.0000000         0.9088797
Four Rooms (1995)        0.9132997        0.9088797         0.0000000</code></pre>
<pre class="r"><code>class(similarity_movies)</code></pre>
<pre><code>[1] &quot;dist&quot;</code></pre>
<p>On peut voir que l’objet résultant est de type <code>"dist"</code>. On note que cet objet peut également servir dans les méthodes de regroupement hierarchiques, entre autre, puisqu’il contient des distances entre observations.</p>
<hr />
<p> <br />
On peut aussi visualiser la similarité sous forme d’une <code>"heatmap"</code> pour les 100 premiers films, avec la fonction .</p>
<pre class="r"><code>image(as.matrix(similarity(MovieLense[,1:100], 
                               method = &quot;cosine&quot;, which = &quot;items&quot;)),
      main = &quot;Movies similarity&quot;)</code></pre>
<p><img src="/post/Rapport_Session_files/figure-html/unnamed-chunk-31-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="construire-un-système-de-recommendation" class="section level2">
<h2>Construire un système de recommendation</h2>
<p>Dans cette partie, nous allons continuer avec la construction d’un <em><strong>S.R.</strong></em> “Item-Based Collaborative filtering”. Pour ce faire, la fonction  va grandement nous aider.<br />
Cette fonction nous permet de séparer l’échantillon. Trois méthodes sont proposés, soit <em></em>, <em></em> et <em></em>. Il faudra fournir la proportion de données utilisé pour entraîner le modèle. Le paramètre <em></em> représente le nombre de films qui seront gardés de façon aléatoire dans l’échantillon test.<br />
Il est important de bien choisir ce paramètre pour la phase d’évaluation. Il doit être plus petit que le nombre minimum d’évaluations faites par un utilisateur, qui est 27 dans notre cas. Nous choisirons 15. Cela veut dire que 15 films seront conservés dans les données connus pour le test.<br />
L’utilité du paramètre <em></em> est expliqué lors de l’évaluation du modèle.</p>
<pre class="r"><code>set.seed(5) 
schema_eval_split &lt;- evaluationScheme(data = data_for_system, 
                                      method = &quot;split&quot;, 
                                      goodRating = 4, train = 0.8, 
                                      k = 1, given = 15) 
print(schema_eval_split)</code></pre>
<pre><code>Evaluation scheme with 15 items given
Method: &#39;split&#39; with 1 run(s).
Training set proportion: 0.800
Good ratings: &gt;=4.000000
Data set: 560 x 434 rating matrix of class &#39;realRatingMatrix&#39; with 63467 ratings.</code></pre>
<hr />
<p> <br />
Une fois notre schéma finalisé, on peut débuter avec la création du <em><strong>S.R.</strong></em>. Afin de savoir les différents algorithmes disponibles, il est possible de consulter le registre des méthodes. Dans notre cas, nous utilisons une realRatingMatrix. Nous allons donc consuler ce registre. Il est aussi possible d’accéder au registre des méthodes pour les binaryRatingMatrix en remplacant <em></em>.<br />
Il est aussi possible d’accéder à la méthode en question afin de connaître les paramètres modifiables.</p>
<pre class="r"><code>reg_modele &lt;- recommenderRegistry$get_entries(dataType = &quot;realRatingMatrix&quot;)  
#print(reg_modele[1:3]) # On ne sort que 3 méthodes, mais il y en a davantage.
#reg_modele$IBCF_realRatingMatrix # C&#39;est la méthode qui nous intéresse</code></pre>
<hr />
<p> <br />
Voulant créer un <em><strong>S.R.</strong></em> “Item-based collaborative filtering”, on va utiliser la fonction . Pour l’exemple, il n’est pas nécessaire de changer les paramètres, mais nous allons changer le <em></em> afin d’illustrer comment faire, ce paramètre détermine le nombre <em></em> des films les plus similaires à un film donné.</p>
<pre class="r"><code># Modèle item-based
itembased_model &lt;- Recommender(data = getData(schema_eval_split,&quot;train&quot;), 
                               method = &quot;IBCF&quot;, parameter = list(k = 20))

# On crée aussi un modèle user-based afin de comparer leurs performances
# Le paramètre &quot;nn&quot; détermine le nombre d&#39;utilisateurs les plus similaires
# à utiliser
userbased_model &lt;- Recommender (data = getData(schema_eval_split,&quot;train&quot;), 
                               method = &quot;UBCF&quot;, parameter = list(nn = 20))</code></pre>
<hr />
<p> <br />
La librairie inclue aussi la fonction  afin d’accéder au modèle créé par . Il est aussi possible d’accéder à des éléments précis qui sont sauvegardés dans l’objet. Par exemple, la ligne de code suivante permet d’accéder à la matrice de similarité qui est conservé dans l’objet.</p>
<pre class="r"><code># Le code n&#39;est pas lancé puisque ça prend trop de place.
# getModel(itembased_model) 
# getModel(itembased_model)$sim</code></pre>
<hr />
<p> <br />
Il est possible de déterminer quels films ont le plus de films similaires selon notre modèle. Par exemple, il est possible de voir que le film suivant aurait 40 films similaires.</p>
<pre class="r"><code>##101 Dalmatiens
colSums(getModel(itembased_model)$sim &gt; 0)[&quot;101 Dalmatians (1996)&quot;] </code></pre>
<pre><code>101 Dalmatians (1996) 
                   40 </code></pre>
<pre class="r"><code># Chaque rangée possède 20 films. 
table(rowSums(getModel(itembased_model)$sim &gt; 0)) </code></pre>
<pre><code>
 20 
434 </code></pre>
<pre class="r"><code># Cela est dû au fait que la méthode conserve 
# les 20 films les plus similaire suite au choix 
# de notre paramètre k = 20 </code></pre>
<hr />
<p> <br />
Aussi, il est possible d’accéder aux films ayant le plus de films similaires. Un histogramme nous permet de voir s’il y a peu de films similaires ou non.</p>
<pre class="r"><code>top_sim &lt;- rownames(getModel(itembased_model)$sim)[order(colSums
                   (getModel(itembased_model)$sim &gt; 0),
                   decreasing = TRUE)[1:5]]
colSums(getModel(itembased_model)$sim &gt; 0)[top_sim] </code></pre>
<pre><code>                 Close Shave, A (1995)   Beautician and the Beast, The (1997) 
                                   131                                    126 
I Know What You Did Last Summer (1997)                 Picture Perfect (1997) 
                                   119                                    113 
                           Bean (1997) 
                                    98 </code></pre>
<pre class="r"><code># On peut constater que peu de films sont 
# similaires en raison de la queue a droite.
qplot(colSums(getModel(itembased_model)$sim &gt; 0),
      colour = I(&quot;#3B444B&quot;),fill=I(&quot;#5D8AA8&quot;), alpha=I(.2))+
  labs(x=&quot;Nombre de films similaires&quot;,y=&quot;Nombre de films&quot;, 
       title=&quot;Distribution du nombre de similarité par film&quot;)+
  theme_classic()</code></pre>
<p><img src="/post/Rapport_Session_files/figure-html/unnamed-chunk-37-1.png" width="65%" style="display: block; margin: auto;" />
***
 <br />
On peut utiliser le modèle pour faire des prédictions sur l’échantillon de test <em></em>. Le modèle va utiliser la matrice de similiraité et les évaluations connues afin de prédire des évaluations pour les films qui n’ont pas été regardé par un utilisateur.<br />
Si on souhaite prédire <em></em> films pour un utilisateur, on utilisera les <em></em> plus grandes évaluations.<br />
La fonction  nous permet de faire les prédictions.<br />
Le paramètre <em></em> de la fonction est le nombre de <em></em> films à recommander.</p>
<pre class="r"><code>pred_sys &lt;- predict(itembased_model, newdata = getData(schema_eval_split,
                                                       &quot;known&quot;), n = 5)
pred_sys </code></pre>
<pre><code>Recommendations as &#39;topNList&#39; with n = 5 for 112 users. </code></pre>
<pre class="r"><code>##On peut aussi consulter les films prédits pour un utilisateur
##Dans ce cas-ci, c&#39;est les 5 films pour l&#39;utilisateur 
pred_sys@itemLabels[pred_sys@items[[1]]]</code></pre>
<pre><code>[1] &quot;Four Rooms (1995)&quot;          &quot;From Dusk Till Dawn (1996)&quot;
[3] &quot;Taxi Driver (1976)&quot;         &quot;Batman Forever (1995)&quot;     
[5] &quot;I.Q. (1994)&quot;               </code></pre>
<hr />
<p> <br />
Afin d’évaluer le <em><strong>S.R.</strong></em>, il faut utiliser la fonction  avec le <em></em>. Cela va nous permettre de créer une <code>realRatingMatrix</code> avec les évaluations estimées.<br />
On peut ensuite utiliser la fonction .<br />
Cette fonction de la librairie nous permet de calculer différentes mesures de performances, soit par utilisateurs ou pour le modèle en général.</p>
<pre class="r"><code>pred_itembased &lt;- predict(itembased_model, 
                    newdata = getData(schema_eval_split,
                                      &quot;known&quot;), type = &quot;ratings&quot;)

##On prédit aussi pour le modèle user-based
pred_userbased &lt;- predict(userbased_model, 
                    newdata = getData(schema_eval_split,
                                      &quot;known&quot;), type = &quot;ratings&quot;)

##On calcule les métriques pour chaque utilisateur pour le item-based
perfo_mod_user &lt;- calcPredictionAccuracy(x = pred_itembased, 
                                    data = getData(schema_eval_split,
                                    &quot;unknown&quot;),byUser = TRUE)

print(perfo_mod_user[1:10,]) #Mesures pour les 10 premiers utilisateurs</code></pre>
<pre><code>        RMSE       MSE       MAE
16 0.8929392 0.7973404 0.5943276
18 1.3259377 1.7581109 1.0541031
23 1.3605767 1.8511690 0.9686149
24 1.0152901 1.0308139 0.6585343
25 0.6891075 0.4748691 0.4867302
38 1.4411534 2.0769231 1.0000000
48 1.3455343 1.8104626 0.9252047
65 1.4167697 2.0072363 1.0637725
69 0.9395998 0.8828479 0.6134353
77 1.9076900 3.6392812 1.5844022</code></pre>
<pre class="r"><code>##On constate qu&#39;on a plusieurs évaluations avec un MAE &gt; 1
qplot(perfo_mod_user[,&quot;MAE&quot;],
      colour = I(&quot;#3B444B&quot;),fill=I(&quot;#5D8AA8&quot;), alpha=I(.2))+
  labs(x=&quot;MAE&quot;,y=&quot;Nombre d&#39;e films&#39;utilisateurs&quot;, 
       title=&quot;Distribution du MAE par utilisateurs&quot;)+
  theme_classic()</code></pre>
<p><img src="/post/Rapport_Session_files/figure-html/unnamed-chunk-39-1.png" width="65%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>perfo_modele_item &lt;- calcPredictionAccuracy(x = pred_itembased, 
                                    data = getData(schema_eval_split, 
                                     &quot;unknown&quot;),byUser = FALSE)
perfo_modele_user &lt;- calcPredictionAccuracy(x = pred_userbased, 
                                    data = getData(schema_eval_split, 
                                     &quot;unknown&quot;),byUser = FALSE)


##On obtient les métriques de performance pour nos modèles afin de les comparer
print(rbind(perfo_modele_item,perfo_modele_user))</code></pre>
<pre><code>                      RMSE      MSE       MAE
perfo_modele_item 1.437174 2.065469 1.0731943
perfo_modele_user 1.014401 1.029010 0.8032682</code></pre>
<pre class="r"><code>##Petit exemple avec evaluate()
perfo_ratings &lt;- evaluate(schema_eval_split, method = &quot;IBCF&quot;, type = &quot;ratings&quot;,
                          parameter = c(k =20))</code></pre>
<pre><code>IBCF run fold/sample [model time/prediction time]
     1  [0.7sec/0.02sec] </code></pre>
<pre class="r"><code>##On constate qu&#39;on arrive au même résultats que plus haut.
print(perfo_ratings@results)</code></pre>
<pre><code>[[1]]
An object of class &quot;confusionMatrix&quot;
Slot &quot;cm&quot;:
        RMSE      MSE      MAE
res 1.437174 2.065469 1.073194

Slot &quot;model&quot;:
NULL</code></pre>
<pre class="r"><code>##On peut aussi utiliser &quot;Top-N&quot; list afin d&#39;évaluer le modèle.
##Pour ce faire, il faut spécifier le paramètre goodRating qui a déja été
##choisi dans notre schéma.
#perfo_topN &lt;- evaluate(schema_eval_split, method = &quot;IBCF&quot;, type = &quot;topNList&quot;,
#                       parameter = c(k =20), n=5)
#print(perfo_topN@results)</code></pre>
<hr />
<p> <br />
Afin de mieux comprendre l’utilité du paramètre <em></em>, voici une explication claire trouvé sur <link><a href="https://github.com/mhahsler/recommenderlab/issues/33"><strong><em></em></strong></a>.</p>
<blockquote>
<p><em></em></p>
</blockquote>
<hr />
<p> <br />
Enfin, on peut noter que le modèle “user-based” prédit mieux les évaluations que le modèle “item-based”. Il est évident que les paramètres n’ont pas été optimisés et qu’il est possible d’améliorer la performance.</p>
<p>Aussi, il est recommandé de lancer plusieurs modèle avec des <code>seeds</code> différents afin de voir si la performance du modèle est stable. Il est aussi possible d’utiliser la fonction  afin d’évaluer plusieurs types de <em><strong>S.R.</strong></em> en même temps.<br />
Il est possible d’évaluer les <em><strong>S.R.</strong></em> selon la prédictions de leurs évaluations ou les “Top-N” films à recommander tel que vu brièvement dans l’exemple.</p>
<p>Dû à un manque d’espace, le lecteur est invité à consulter la documentation très claire de la librairie, ainsi que les différentes ressources documentées dans ce rapport.</p>

</div>
</div>
<div id="bibliographie" class="section level1">
<h1>Bibliographie</h1>
<p>[1] </p>
<p>[2] </p>
<p>[3] </p>
<p>[4] </p>
<p>[5] </p>
<p>[6] </p>
<p>[7] </p>
<p>[8] </p>
<p>[9] </p>
<p>[10] </p>
<p>[11] </p>
<p>[12] </p>
<p>[13] </p>
<p>[14] </p>
<p>[15] </p>
<p>[16] </p>
<p>[17] </p>
<p>[18] </p>
<p>[19] </p>
<p>[20] </p>
<p>[21] </p>
<p>[22] </p>
<p>[23] </p>
<p>[24] </p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p><a href="https://www.mckinsey.com/industries/retail/our-insights/how-retailers-can-keep-up-with-consumers" class="uri">https://www.mckinsey.com/industries/retail/our-insights/how-retailers-can-keep-up-with-consumers</a><a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p><a href="https://www.inf.unibz.it/~ricci/ISR/papers/ieeecomputer.pdf" class="uri">https://www.inf.unibz.it/~ricci/ISR/papers/ieeecomputer.pdf</a><a href="#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>Cela pose problème en classification puisque les observations d’une même classe sont sous-représenté et le taux de bonne classification sera bon alors que le taux de faux positifs ou négatifs sera élevé.<a href="#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p><a href="https://gist.github.com/talegari/77c90db326b4848368287e53b1a18e8d" class="uri">https://gist.github.com/talegari/77c90db326b4848368287e53b1a18e8d</a><a href="#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p><a href="https://github.com/ludovikcoba/rrecsys" class="uri">https://github.com/ludovikcoba/rrecsys</a><a href="#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p><a href="https://github.com/yixuan/recosystem" class="uri">https://github.com/yixuan/recosystem</a><a href="#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p><a href="https://github.com/yixuan/recosystem" class="uri">https://github.com/yixuan/recosystem</a><a href="#fnref7" class="footnote-back">↩</a></p></li>
<li id="fn8"><p><a href="https://github.com/mhahsler/recommenderlab" class="uri">https://github.com/mhahsler/recommenderlab</a><a href="#fnref8" class="footnote-back">↩</a></p></li>
</ol>
</div>
